{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "QecIVrSOSmon",
        "outputId": "a38fe181-c393-4707-fc84-f3f0193af361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-205880319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ No training data found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-205880319.py\u001b[0m in \u001b[0;36mload_faces\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign_and_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-205880319.py\u001b[0m in \u001b[0;36malign_and_normalize\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m\"\"\"Detect and crop face, equalize lighting.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaleFactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install pillow-heif tensorflow keras opencv-python-headless pandas --quiet\n",
        "\n",
        "from google.colab import drive\n",
        "import os, cv2, numpy as np, pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import pillow_heif\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==========================================\n",
        "# STEP 1: Mount Drive\n",
        "# ==========================================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/faces_dataset\"\n",
        "group_folder = os.path.join(base_path, \"group_photo\")\n",
        "model_path = os.path.join(base_path, \"trained_face_model_v3.h5\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 2: Convert HEIC → JPG (if any)\n",
        "# ==========================================\n",
        "def convert_heic_to_jpg(folder):\n",
        "    pillow_heif.register_heif_opener()\n",
        "    for file in os.listdir(folder):\n",
        "        if file.lower().endswith(\".heic\"):\n",
        "            heic_path = os.path.join(folder, file)\n",
        "            jpg_path = heic_path.replace(\".HEIC\", \".jpg\").replace(\".heic\", \".jpg\")\n",
        "            try:\n",
        "                img = Image.open(heic_path)\n",
        "                img.save(jpg_path, \"JPEG\")\n",
        "                os.remove(heic_path)\n",
        "                print(f\"✅ Converted {file} → {os.path.basename(jpg_path)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error converting {file}: {e}\")\n",
        "\n",
        "for d in os.listdir(base_path):\n",
        "    f = os.path.join(base_path, d)\n",
        "    if os.path.isdir(f):\n",
        "        convert_heic_to_jpg(f)\n",
        "\n",
        "# ==========================================\n",
        "# STEP 3: Face alignment helper\n",
        "# ==========================================\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def align_and_normalize(img):\n",
        "    \"\"\"Detect and crop face, equalize lighting.\"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n",
        "    if len(faces) > 0:\n",
        "        faces = sorted(faces, key=lambda x: x[2]*x[3], reverse=True)\n",
        "        x, y, w, h = faces[0]\n",
        "        face = img[y:y+h, x:x+w]\n",
        "        yuv = cv2.cvtColor(face, cv2.COLOR_BGR2YUV)\n",
        "        yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])\n",
        "        return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
        "    return img\n",
        "\n",
        "# ==========================================\n",
        "# STEP 4: Load faces from folders\n",
        "# ==========================================\n",
        "def load_faces(base_path):\n",
        "    imgs, labels, names = [], [], []\n",
        "    person_dirs = sorted([d for d in os.listdir(base_path)\n",
        "                          if os.path.isdir(os.path.join(base_path, d)) and d != \"group_photo\"])\n",
        "    for idx, person in enumerate(person_dirs):\n",
        "        p_path = os.path.join(base_path, person)\n",
        "        names.append(person)\n",
        "        for f in os.listdir(p_path):\n",
        "            if f.lower().endswith(('.jpg','.jpeg','.png')):\n",
        "                img_path = os.path.join(p_path, f)\n",
        "                try:\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None: continue\n",
        "                    face = align_and_normalize(img)\n",
        "                    face = cv2.resize(face, (100, 100))\n",
        "                    imgs.append(face)\n",
        "                    labels.append(idx)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {img_path}: {e}\")\n",
        "    print(f\"✅ Loaded {len(imgs)} images across {len(names)} classes: {names}\")\n",
        "    return np.array(imgs), np.array(labels), names\n",
        "\n",
        "X, y, names = load_faces(base_path)\n",
        "if len(X) == 0:\n",
        "    print(\"❌ No training data found.\")\n",
        "    raise SystemExit\n",
        "\n",
        "X = X.astype('float32')/255.0\n",
        "y = to_categorical(y, len(names))\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ==========================================\n",
        "# STEP 5: Build & Train Model\n",
        "# ==========================================\n",
        "model = Sequential([\n",
        "    Conv2D(64, (3,3), activation='relu', input_shape=(100,100,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(names), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=8, validation_data=(X_val, y_val))\n",
        "model.save(model_path)\n",
        "print(\"✅ Model trained & saved at:\", model_path)\n",
        "\n",
        "# ==========================================\n",
        "# STEP 6: Skin-tone filtering helper\n",
        "# ==========================================\n",
        "def skin_mask(bgr_img):\n",
        "    \"\"\"Return binary mask for skin-like pixels using HSV & YCrCb thresholds.\"\"\"\n",
        "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
        "    ycrcb = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # HSV skin range\n",
        "    lower_hsv = np.array([0, 30, 60], dtype=np.uint8)\n",
        "    upper_hsv = np.array([20, 150, 255], dtype=np.uint8)\n",
        "    mask_hsv = cv2.inRange(hsv, lower_hsv, upper_hsv)\n",
        "\n",
        "    # YCrCb skin range\n",
        "    lower_ycrcb = np.array([0, 133, 77], dtype=np.uint8)\n",
        "    upper_ycrcb = np.array([255, 173, 127], dtype=np.uint8)\n",
        "    mask_ycrcb = cv2.inRange(ycrcb, lower_ycrcb, upper_ycrcb)\n",
        "\n",
        "    combined_mask = cv2.bitwise_and(mask_hsv, mask_ycrcb)\n",
        "    combined_mask = cv2.medianBlur(combined_mask, 5)\n",
        "    return combined_mask\n",
        "\n",
        "# ==========================================\n",
        "# STEP 7: Detect faces in group photo\n",
        "# ==========================================\n",
        "def detect_faces_in_group(image_path, model, names, threshold=0.5):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"❌ Could not load image:\", image_path)\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1,\n",
        "                                          minNeighbors=6, minSize=(50,50))\n",
        "    results = []\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_img = img[y:y+h, x:x+w]\n",
        "\n",
        "        # Step 1: Check if region is mostly skin-colored\n",
        "        mask = skin_mask(face_img)\n",
        "        skin_ratio = np.sum(mask > 0) / (mask.size)\n",
        "        if skin_ratio < 0.15:  # skip if not enough skin pixels\n",
        "            continue\n",
        "\n",
        "        # Step 2: Classify\n",
        "        face_resized = cv2.resize(face_img, (100, 100)) / 255.0\n",
        "        face_resized = np.expand_dims(face_resized, axis=0)\n",
        "        preds = model.predict(face_resized, verbose=0)\n",
        "        label_idx = np.argmax(preds)\n",
        "        prob = preds[0][label_idx]\n",
        "\n",
        "        # Step 3: Only draw if confidence >= threshold\n",
        "        if prob >= threshold:\n",
        "            label = names[label_idx]\n",
        "            color = (0, 255, 0)\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), color, 3)\n",
        "            cv2.putText(img, f\"{label} ({prob:.2f})\", (x, y-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
        "            results.append([x, y, w, h, label, round(float(prob), 4)])\n",
        "        # Skip drawing if prob < threshold → no box shown\n",
        "\n",
        "    output_img_path = \"/content/group_photo_predictions_v3.jpg\"\n",
        "    cv2.imwrite(output_img_path, img)\n",
        "    df = pd.DataFrame(results, columns=[\"x\",\"y\",\"w\",\"h\",\"label\",\"probability\"])\n",
        "    df.to_csv(\"predictions_v3.csv\", index=False)\n",
        "    print(\"✅ Saved annotated image at:\", output_img_path)\n",
        "    print(\"✅ Predictions saved to predictions_v3.csv\")\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# STEP 8: Run detection\n",
        "# ==========================================\n",
        "group_photo_path = os.path.join(group_folder, \"IMG_1473.jpg\")\n",
        "preds_df = detect_faces_in_group(group_photo_path, model, names, threshold=0.5)\n",
        "print(\"\\nPredictions Summary:\")\n",
        "print(preds_df.head())\n"
      ]
    }
  ]
}